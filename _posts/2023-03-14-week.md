---
title: '周小结(2023.03.08-2023.03.14)'
date: 2023-03-14
permalink: /posts/2023-03-14_week/
---
| title                                                                                               | journal    | content                                                                                            | conclusion                                                                                        | gain                                                                                                |
|:----------------------------------------------------------------------------------------------------|:-----------|:---------------------------------------------------------------------------------------------------|:--------------------------------------------------------------------------------------------------|:----------------------------------------------------------------------------------------------------|
| Enhancing the Locality and Breaking the Memory Bottleneck of Transformer on Time Series Forecasting | NLPS 2019  | 提出了卷积自注意和LogSparse Transformer来解决Transformer在时序数据上的局部不可知论和内存瓶颈问题。 | 卷积自注意通过因果卷积提高局部上下文敏感性，LogSparse Transformer通过堆叠自注意力层减少内存成本。 | 在网络中复现实验，发现与GRU效果相当，支持并行加速训练，且对不同时间频率信息有层次化的关注。         |
| Conformer: Local Features Coupling Global Representations for Visual Recognition                    | arxiv 2021 | 结合卷积和Transformer的特性，通过dual网络结构和Feature Coupling Unit来融合局部和全局特征。         | 通过并行的卷积和Transformer分支以及FCU交互融合，保留并增强两种特征的互补性。                      | 解决单独Transformer训练困难的问题，显示融合结构在图像识别任务上的潜力，考虑将其应用于时序数据处理。 |


![image](/files/post/2023-03-14-week/0.jpg)
![image](/files/post/2023-03-14-week/1.jpg)
![image](/files/post/2023-03-14-week/2.jpg)
![image](/files/post/2023-03-14-week/3.jpg)
![image](/files/post/2023-03-14-week/4.jpg)
![image](/files/post/2023-03-14-week/5.jpg)