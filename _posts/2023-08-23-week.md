---
title: '周小结(2023.08.18-2023.08.23)'
date: 2023-08-23
permalink: /posts/2023-08-23_week/
---
| title                                                                                             | journal   | content                                                                                                                                  | conclusion                                                         | gain                                                                         |
|:--------------------------------------------------------------------------------------------------|:----------|:-----------------------------------------------------------------------------------------------------------------------------------------|:-------------------------------------------------------------------|:-----------------------------------------------------------------------------|
| Vision-and-Language or Vision-for-Language? On Cross-Modal Inflfluence in Multimodal Transformers | arxiv     | 提出了Multimodal Bottleneck Transformer(MBT)，通过自注意力机制在中间层促进多模态信息交换，引入跨模态输入消融方法量化跨模态信息使用程度。 | 模型展示出不对称的跨模态影响，更倾向于使用视觉信息来增强语言理解。 | 了解了MBT架构及跨模态信息交互的不对称性，对多模态模型中的信息流有了新认识。  |
| Attention Bottlenecks for Multimodal Fusion                                                       | NIPS      | 提出一种基于Transformer的架构，通过融合瓶颈(latents)实现模态间信息压缩与交流。                                                           | 多模态融合通过限制信息通道促进了模态间的高效信息传递。             | 学习了多模态融合策略，特别是融合瓶颈的概念，对后续研究多模态信息融合有启发。 |

<embed src="/files/post/2023-08-23-week.pdf" type="application/pdf" height="400px" />
    